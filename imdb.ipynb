{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-26T13:42:54.619861300Z",
     "start_time": "2023-06-26T13:42:43.005410300Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 7s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T13:43:05.757111700Z",
     "start_time": "2023-06-26T13:42:54.614711700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "9999"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T13:43:05.914200900Z",
     "start_time": "2023-06-26T13:43:05.763134200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1641221/1641221 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"? lavish production values and solid performances in this straightforward adaption of jane ? satirical classic about the marriage game within and between the classes in ? 18th century england northam and paltrow are a ? mixture as friends who must pass through ? and lies to discover that they love each other good humor is a ? virtue which goes a long way towards explaining the ? of the aged source material which has been toned down a bit in its harsh ? i liked the look of the film and how shots were set up and i thought it didn't rely too much on ? of head shots like most other films of the 80s and 90s do very good results\""
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "decoded_review = ' '.join(\n",
    "    [reverse_word_index.get(i - 3, '?') for i in train_data[6]])\n",
    "decoded_review"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T13:43:06.902825600Z",
     "start_time": "2023-06-26T13:43:05.904657Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[1,\n 14,\n 22,\n 16,\n 43,\n 530,\n 973,\n 1622,\n 1385,\n 65,\n 458,\n 4468,\n 66,\n 3941,\n 4,\n 173,\n 36,\n 256,\n 5,\n 25,\n 100,\n 43,\n 838,\n 112,\n 50,\n 670,\n 2,\n 9,\n 35,\n 480,\n 284,\n 5,\n 150,\n 4,\n 172,\n 112,\n 167,\n 2,\n 336,\n 385,\n 39,\n 4,\n 172,\n 4536,\n 1111,\n 17,\n 546,\n 38,\n 13,\n 447,\n 4,\n 192,\n 50,\n 16,\n 6,\n 147,\n 2025,\n 19,\n 14,\n 22,\n 4,\n 1920,\n 4613,\n 469,\n 4,\n 22,\n 71,\n 87,\n 12,\n 16,\n 43,\n 530,\n 38,\n 76,\n 15,\n 13,\n 1247,\n 4,\n 22,\n 17,\n 515,\n 17,\n 12,\n 16,\n 626,\n 18,\n 2,\n 5,\n 62,\n 386,\n 12,\n 8,\n 316,\n 8,\n 106,\n 5,\n 4,\n 2223,\n 5244,\n 16,\n 480,\n 66,\n 3785,\n 33,\n 4,\n 130,\n 12,\n 16,\n 38,\n 619,\n 5,\n 25,\n 124,\n 51,\n 36,\n 135,\n 48,\n 25,\n 1415,\n 33,\n 6,\n 22,\n 12,\n 215,\n 28,\n 77,\n 52,\n 5,\n 14,\n 407,\n 16,\n 82,\n 2,\n 8,\n 4,\n 107,\n 117,\n 5952,\n 15,\n 256,\n 4,\n 2,\n 7,\n 3766,\n 5,\n 723,\n 36,\n 71,\n 43,\n 530,\n 476,\n 26,\n 400,\n 317,\n 46,\n 7,\n 4,\n 2,\n 1029,\n 13,\n 104,\n 88,\n 4,\n 381,\n 15,\n 297,\n 98,\n 32,\n 2071,\n 56,\n 26,\n 141,\n 6,\n 194,\n 7486,\n 18,\n 4,\n 226,\n 22,\n 21,\n 134,\n 476,\n 26,\n 480,\n 5,\n 144,\n 30,\n 5535,\n 18,\n 51,\n 36,\n 28,\n 224,\n 92,\n 25,\n 104,\n 4,\n 226,\n 65,\n 16,\n 38,\n 1334,\n 88,\n 12,\n 16,\n 283,\n 5,\n 16,\n 4472,\n 113,\n 103,\n 32,\n 15,\n 16,\n 5345,\n 19,\n 178,\n 32]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T13:43:06.993011500Z",
     "start_time": "2023-06-26T13:43:06.908379700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T13:43:09.838803700Z",
     "start_time": "2023-06-26T13:43:06.939001300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T13:43:09.853348800Z",
     "start_time": "2023-06-26T13:43:09.840807Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T13:43:10.243347900Z",
     "start_time": "2023-06-26T13:43:09.860359200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T13:43:10.285447400Z",
     "start_time": "2023-06-26T13:43:10.247868400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T13:43:10.304515200Z",
     "start_time": "2023-06-26T13:43:10.281445200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 3s 55ms/step - loss: 0.5283 - acc: 0.7759 - val_loss: 0.3971 - val_acc: 0.8665\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.3257 - acc: 0.8937 - val_loss: 0.3137 - val_acc: 0.8810\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.2442 - acc: 0.9176 - val_loss: 0.2903 - val_acc: 0.8847\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.1961 - acc: 0.9355 - val_loss: 0.2805 - val_acc: 0.8844\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.1645 - acc: 0.9448 - val_loss: 0.2769 - val_acc: 0.8876\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1394 - acc: 0.9552 - val_loss: 0.2858 - val_acc: 0.8864\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1223 - acc: 0.9595 - val_loss: 0.2968 - val_acc: 0.8849\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.1045 - acc: 0.9679 - val_loss: 0.3138 - val_acc: 0.8819\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0899 - acc: 0.9732 - val_loss: 0.3337 - val_acc: 0.8810\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0754 - acc: 0.9784 - val_loss: 0.4061 - val_acc: 0.8616\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0692 - acc: 0.9807 - val_loss: 0.3890 - val_acc: 0.8757\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0545 - acc: 0.9881 - val_loss: 0.4175 - val_acc: 0.8724\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0483 - acc: 0.9885 - val_loss: 0.4005 - val_acc: 0.8760\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0412 - acc: 0.9914 - val_loss: 0.4264 - val_acc: 0.8742\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0402 - acc: 0.9901 - val_loss: 0.4464 - val_acc: 0.8753\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0258 - acc: 0.9963 - val_loss: 0.4687 - val_acc: 0.8741\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0291 - acc: 0.9949 - val_loss: 0.4921 - val_acc: 0.8728\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0219 - acc: 0.9966 - val_loss: 0.5089 - val_acc: 0.8709\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0192 - acc: 0.9973 - val_loss: 0.5263 - val_acc: 0.8707\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0154 - acc: 0.9986 - val_loss: 0.5507 - val_acc: 0.8705\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T13:43:23.475014400Z",
     "start_time": "2023-06-26T13:43:10.298506200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T13:43:43.408535400Z",
     "start_time": "2023-06-26T13:43:37.968470300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-26T13:43:23.499728400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "decoded_review = ' '.join(\n",
    "    [reverse_word_index.get(i - 3, '?') for i in train_data[6]])\n",
    "decoded_review"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-26T13:43:23.505724800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-26T13:43:23.512283700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-26T13:43:23.518838600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-26T13:43:23.524825700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-26T13:43:23.531080700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check data is correct\n",
    "testloss, testacc = model.evaluate(x_test, y_test)\n",
    "print(testacc, testloss)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
